{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BRISQUE score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BRISQUE\n",
    "#Blind/Referenceless Image Spatial Quality Evaluator\n",
    "#Single number score for image quality (to facilitate comparing photos and selecting 'best' photo)\n",
    "\n",
    "'''\n",
    "add to requirements.txt !!!!!!! _> #pip install brisque\n",
    "'''\n",
    "#pip install brisque\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from brisque import BRISQUE\n",
    "\n",
    "# Load the image using PIL\n",
    "image_path = '/home/gregrevill/code/GregRevFr/photopocalypse/raw_data/input_images/DSC_0797.JPG'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Convert the image to RGB (if it's not already)\n",
    "image = image.convert('RGB')\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "image_array = np.array(image)\n",
    "\n",
    "# Calculate the BRISQUE score\n",
    "brisque_score = BRISQUE().score(image_array)\n",
    "\n",
    "print(f\"BRISQUE score for the image is: {brisque_score}\")\n",
    "\n",
    "#For Image via URL :\n",
    "#obj = BRISQUE(url=True).score(\"https://images.ctfassets.net/u4vv676b8z52/4dy4qSI9G77nmLayGrUl73/08fdde4d35a717c7e9d123ef2a478e9b/blurred-vision-678x446_compressed.jpg?fm=jpg&q=80\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BRISQUE score for multiple images in a folder (with error avoidance code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from brisque import BRISQUE\n",
    "import pandas as pd\n",
    "\n",
    "# Function to process a single image\n",
    "def process_image(image_file):\n",
    "    # Construct the full image path\n",
    "    image_path = os.path.join(image_dir, image_file)\n",
    "\n",
    "    # Check if the path is a file and is a recognized image format\n",
    "    if os.path.isfile(image_path) and image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        try:\n",
    "            # Load the image using PIL\n",
    "            image = Image.open(image_path)\n",
    "\n",
    "            # Convert the image to RGB (if it's not already)\n",
    "            image = image.convert('RGB')\n",
    "\n",
    "            # Resize the image\n",
    "            image = image.resize((256, 256))\n",
    "\n",
    "            # Convert the image to a numpy array\n",
    "            image_array = np.array(image)\n",
    "\n",
    "            # Calculate the BRISQUE score\n",
    "            brisque_score = BRISQUE().score(image_array)\n",
    "\n",
    "            return (image_file, brisque_score)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {image_file}: {e}\")\n",
    "\n",
    "# Directory containing the images\n",
    "image_dir = \"/home/gregrevill/code/GregRevFr/photopocalypse/raw_data/input_images/\"\n",
    "\n",
    "# List all the files in the directory\n",
    "image_files = os.listdir(image_dir)\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Process each image file\n",
    "for image_file in image_files:\n",
    "    result = process_image(image_file)\n",
    "    if result is not None:\n",
    "        results.append(result)\n",
    "\n",
    "# Convert the results to a pandas DataFrame\n",
    "df = pd.DataFrame(results, columns=['Image', 'BRISQUE Score'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/home/gregrevill/code/GregRevFr/photopocalypse/raw_data/brisque_scores2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiling for Deblur model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 10:11:47.540523: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Descriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/gregrevill/code/GregRevFr/photopocalypse/notebooks/notebook_greg.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gregrevill/code/GregRevFr/photopocalypse/notebooks/notebook_greg.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gregrevill/code/GregRevFr/photopocalypse/notebooks/notebook_greg.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mModel to deblur images, using EDSR.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gregrevill/code/GregRevFr/photopocalypse/notebooks/notebook_greg.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mtakes image from EDI\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gregrevill/code/GregRevFr/photopocalypse/notebooks/notebook_greg.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mand remove padding from the enhanced image.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gregrevill/code/GregRevFr/photopocalypse/notebooks/notebook_greg.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gregrevill/code/GregRevFr/photopocalypse/notebooks/notebook_greg.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gregrevill/code/GregRevFr/photopocalypse/notebooks/notebook_greg.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gregrevill/code/GregRevFr/photopocalypse/notebooks/notebook_greg.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m load_model\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gregrevill/code/GregRevFr/photopocalypse/notebooks/notebook_greg.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/__init__.py:37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     40\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/__init__.py:37\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[39m# go/tf-wildcard-import\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow \u001b[39mas\u001b[39;00m _pywrap_tensorflow\n\u001b[0;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[1;32m     39\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[39m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/context.py:29\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msix\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m function_pb2\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprotobuf\u001b[39;00m \u001b[39mimport\u001b[39;00m config_pb2\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprotobuf\u001b[39;00m \u001b[39mimport\u001b[39;00m coordination_config_pb2\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/function_pb2.py:16\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m _sym_db \u001b[39m=\u001b[39m _symbol_database\u001b[39m.\u001b[39mDefault()\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m attr_value_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_attr__value__pb2\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m node_def_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_node__def__pb2\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m op_def_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_op__def__pb2\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/attr_value_pb2.py:16\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m _sym_db \u001b[39m=\u001b[39m _symbol_database\u001b[39m.\u001b[39mDefault()\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_tensor__pb2\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_shape_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m types_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_types__pb2\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py:16\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m _sym_db \u001b[39m=\u001b[39m _symbol_database\u001b[39m.\u001b[39mDefault()\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m resource_handle_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_resource__handle__pb2\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_shape_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m types_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_types__pb2\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py:16\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m _sym_db \u001b[39m=\u001b[39m _symbol_database\u001b[39m.\u001b[39mDefault()\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_shape_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m types_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_types__pb2\n\u001b[1;32m     20\u001b[0m DESCRIPTOR \u001b[39m=\u001b[39m _descriptor\u001b[39m.\u001b[39mFileDescriptor(\n\u001b[1;32m     21\u001b[0m   name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow/core/framework/resource_handle.proto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     22\u001b[0m   package\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m   ,\n\u001b[1;32m     27\u001b[0m   dependencies\u001b[39m=\u001b[39m[tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\u001b[39m.\u001b[39mDESCRIPTOR,tensorflow_dot_core_dot_framework_dot_types__pb2\u001b[39m.\u001b[39mDESCRIPTOR,])\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:36\u001b[0m\n\u001b[1;32m     13\u001b[0m _sym_db \u001b[39m=\u001b[39m _symbol_database\u001b[39m.\u001b[39mDefault()\n\u001b[1;32m     18\u001b[0m DESCRIPTOR \u001b[39m=\u001b[39m _descriptor\u001b[39m.\u001b[39mFileDescriptor(\n\u001b[1;32m     19\u001b[0m   name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow/core/framework/tensor_shape.proto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m   package\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m   serialized_pb\u001b[39m=\u001b[39m_b(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m,tensorflow/core/framework/tensor_shape.proto\u001b[39m\u001b[39m\\x12\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mtensorflow\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39mz\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x10\u001b[39;00m\u001b[39mTensorShapeProto\u001b[39m\u001b[39m\\x12\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x03\u001b[39;00m\u001b[39m\\x64\u001b[39;00m\u001b[39mim\u001b[39m\u001b[39m\\x18\u001b[39;00m\u001b[39m\\x02\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\x03\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m\\x0b\u001b[39;00m\u001b[39m\\x32\u001b[39;00m\u001b[39m .tensorflow.TensorShapeProto.Dim\u001b[39m\u001b[39m\\x12\u001b[39;00m\u001b[39m\\x14\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x0c\u001b[39;00m\u001b[39munknown_rank\u001b[39m\u001b[39m\\x18\u001b[39;00m\u001b[39m\\x03\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\x01\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m\\x08\u001b[39;00m\u001b[39m\\x1a\u001b[39;00m\u001b[39m!\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x03\u001b[39;00m\u001b[39m\\x44\u001b[39;00m\u001b[39mim\u001b[39m\u001b[39m\\x12\u001b[39;00m\u001b[39m\\x0c\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x04\u001b[39;00m\u001b[39msize\u001b[39m\u001b[39m\\x18\u001b[39;00m\u001b[39m\\x01\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\x01\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m\\x03\u001b[39;00m\u001b[39m\\x12\u001b[39;00m\u001b[39m\\x0c\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x04\u001b[39;00m\u001b[39mname\u001b[39m\u001b[39m\\x18\u001b[39;00m\u001b[39m\\x02\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\x01\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mB\u001b[39m\u001b[39m\\x87\u001b[39;00m\u001b[39m\\x01\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x18\u001b[39;00m\u001b[39morg.tensorflow.frameworkB\u001b[39m\u001b[39m\\x11\u001b[39;00m\u001b[39mTensorShapeProtosP\u001b[39m\u001b[39m\\x01\u001b[39;00m\u001b[39mZSgithub.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto\u001b[39m\u001b[39m\\xf8\u001b[39;00m\u001b[39m\\x01\u001b[39;00m\u001b[39m\\x01\u001b[39;00m\u001b[39m\\x62\u001b[39;00m\u001b[39m\\x06\u001b[39;00m\u001b[39mproto3\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     29\u001b[0m _TENSORSHAPEPROTO_DIM \u001b[39m=\u001b[39m _descriptor\u001b[39m.\u001b[39mDescriptor(\n\u001b[1;32m     30\u001b[0m   name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDim\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     31\u001b[0m   full_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow.TensorShapeProto.Dim\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     32\u001b[0m   filename\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     33\u001b[0m   file\u001b[39m=\u001b[39mDESCRIPTOR,\n\u001b[1;32m     34\u001b[0m   containing_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     35\u001b[0m   fields\u001b[39m=\u001b[39m[\n\u001b[0;32m---> 36\u001b[0m     _descriptor\u001b[39m.\u001b[39;49mFieldDescriptor(\n\u001b[1;32m     37\u001b[0m       name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msize\u001b[39;49m\u001b[39m'\u001b[39;49m, full_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtensorflow.TensorShapeProto.Dim.size\u001b[39;49m\u001b[39m'\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     38\u001b[0m       number\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39mtype\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, cpp_type\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, label\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     39\u001b[0m       has_default_value\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, default_value\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     40\u001b[0m       message_type\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, enum_type\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, containing_type\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     41\u001b[0m       is_extension\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, extension_scope\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     42\u001b[0m       serialized_options\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, file\u001b[39m=\u001b[39;49mDESCRIPTOR),\n\u001b[1;32m     43\u001b[0m     _descriptor\u001b[39m.\u001b[39mFieldDescriptor(\n\u001b[1;32m     44\u001b[0m       name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m, full_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow.TensorShapeProto.Dim.name\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     45\u001b[0m       number\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m9\u001b[39m, cpp_type\u001b[39m=\u001b[39m\u001b[39m9\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     46\u001b[0m       has_default_value\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, default_value\u001b[39m=\u001b[39m_b(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     47\u001b[0m       message_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, enum_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, containing_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m       is_extension\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, extension_scope\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     49\u001b[0m       serialized_options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, file\u001b[39m=\u001b[39mDESCRIPTOR),\n\u001b[1;32m     50\u001b[0m   ],\n\u001b[1;32m     51\u001b[0m   extensions\u001b[39m=\u001b[39m[\n\u001b[1;32m     52\u001b[0m   ],\n\u001b[1;32m     53\u001b[0m   nested_types\u001b[39m=\u001b[39m[],\n\u001b[1;32m     54\u001b[0m   enum_types\u001b[39m=\u001b[39m[\n\u001b[1;32m     55\u001b[0m   ],\n\u001b[1;32m     56\u001b[0m   serialized_options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     57\u001b[0m   is_extendable\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     58\u001b[0m   syntax\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mproto3\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     59\u001b[0m   extension_ranges\u001b[39m=\u001b[39m[],\n\u001b[1;32m     60\u001b[0m   oneofs\u001b[39m=\u001b[39m[\n\u001b[1;32m     61\u001b[0m   ],\n\u001b[1;32m     62\u001b[0m   serialized_start\u001b[39m=\u001b[39m\u001b[39m149\u001b[39m,\n\u001b[1;32m     63\u001b[0m   serialized_end\u001b[39m=\u001b[39m\u001b[39m182\u001b[39m,\n\u001b[1;32m     64\u001b[0m )\n\u001b[1;32m     66\u001b[0m _TENSORSHAPEPROTO \u001b[39m=\u001b[39m _descriptor\u001b[39m.\u001b[39mDescriptor(\n\u001b[1;32m     67\u001b[0m   name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTensorShapeProto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     68\u001b[0m   full_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow.TensorShapeProto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m   serialized_end\u001b[39m=\u001b[39m\u001b[39m182\u001b[39m,\n\u001b[1;32m    101\u001b[0m )\n\u001b[1;32m    103\u001b[0m _TENSORSHAPEPROTO_DIM\u001b[39m.\u001b[39mcontaining_type \u001b[39m=\u001b[39m _TENSORSHAPEPROTO\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/google/protobuf/descriptor.py:553\u001b[0m, in \u001b[0;36mFieldDescriptor.__new__\u001b[0;34m(cls, name, full_name, index, number, type, cpp_type, label, default_value, message_type, enum_type, containing_type, is_extension, extension_scope, options, serialized_options, has_default_value, containing_oneof, json_name, file, create_key)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m, name, full_name, index, number, \u001b[39mtype\u001b[39m, cpp_type, label,\n\u001b[1;32m    548\u001b[0m             default_value, message_type, enum_type, containing_type,\n\u001b[1;32m    549\u001b[0m             is_extension, extension_scope, options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    550\u001b[0m             serialized_options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    551\u001b[0m             has_default_value\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, containing_oneof\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, json_name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    552\u001b[0m             file\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, create_key\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):  \u001b[39m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m   _message\u001b[39m.\u001b[39;49mMessage\u001b[39m.\u001b[39;49m_CheckCalledFromGeneratedFile()\n\u001b[1;32m    554\u001b[0m   \u001b[39mif\u001b[39;00m is_extension:\n\u001b[1;32m    555\u001b[0m     \u001b[39mreturn\u001b[39;00m _message\u001b[39m.\u001b[39mdefault_pool\u001b[39m.\u001b[39mFindExtensionByName(full_name)\n",
      "\u001b[0;31mTypeError\u001b[0m: Descriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Model to deblur images, using EDSR.\n",
    "takes image from EDI\n",
    "    nparr = np.frombuffer(contents, np.uint8) # convert string data to np array\n",
    "    image = cv2.imdecode(nparr, cv2.IMREAD_COLOR) # convert np array to image\n",
    "if the input image is larger than 768x768 then it scales the image down so longest side is 768 pixels,\n",
    "then pads short side to reach 768 pixels,\n",
    "then splits padded image into 9 tiles,\n",
    "process each tile individually,\n",
    "then reconstruct the enhanced image from the enhanced patches\n",
    "and remove padding from the enhanced image.\n",
    "'''\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# initial model_path = '/home/gregrevill/code/GregRevFr/photopocalypse/models/SRresnet-from-kaggle-trained-on-blur.h5'\n",
    "# paulo model model_path = '/home/gregrevill/code/GregRevFr/photopocalypse/models/EDSR_blur_dataset_model_2.h5'\n",
    "model_path = '/home/gregrevill/code/GregRevFr/photopocalypse/models/gen_model3000.h5'\n",
    "image_path = '/home/gregrevill/code/GregRevFr/photopocalypse/raw_data/input_images/DSC_0797.JPG'\n",
    "model = load_model(model_path)\n",
    "tile_size = 256\n",
    "number_of_tiles = 9\n",
    "\n",
    "def deblur_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Resize if larger than 768x768\n",
    "    max_side = tile_size * int(number_of_tiles ** 0.5)\n",
    "    scale_factor = min(max_side / image.shape[0], max_side / image.shape[1])\n",
    "    if scale_factor < 1:\n",
    "        new_size = (int(image.shape[1] * scale_factor), int(image.shape[0] * scale_factor))\n",
    "        image = cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Padding\n",
    "    original_height, original_width = image.shape[:2]\n",
    "    pad_height = (tile_size - image.shape[0] % tile_size) % tile_size\n",
    "    pad_width = (tile_size - image.shape[1] % tile_size) % tile_size\n",
    "    image = cv2.copyMakeBorder(image, 0, pad_height, 0, pad_width, cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "    # Split into tiles\n",
    "    tiles = []\n",
    "    for i in range(0, image.shape[0], tile_size):\n",
    "        for j in range(0, image.shape[1], tile_size):\n",
    "            tile = image[i:i + tile_size, j:j + tile_size]\n",
    "            tiles.append(tile)\n",
    "\n",
    "    # Predict and enhance each tile\n",
    "    # skip predict step for now\n",
    "    # enhanced_tiles = [model.predict(np.expand_dims(tile, 0))[0] for tile in tiles]\n",
    "    enhanced_tiles = [(model.predict(np.expand_dims(tile / 255., 0)) * 255)[0].astype(np.uint8) for tile in tiles]\n",
    "    # enhanced_tiles = tiles  # Using the original tiles for now\n",
    "\n",
    "    # Reconstruct the enhanced image\n",
    "    rows = []\n",
    "    for i in range(0, len(enhanced_tiles), int(image.shape[1] / tile_size)):\n",
    "        rows.append(np.hstack(enhanced_tiles[i:i + int(image.shape[1] / tile_size)]))\n",
    "    enhanced_image = np.vstack(rows)\n",
    "\n",
    "    # Calculate the actual enhanced image dimensions after padding\n",
    "    actual_enhanced_height = original_height + pad_height\n",
    "    actual_enhanced_width = original_width + pad_width\n",
    "\n",
    "    # Remove padding\n",
    "    enhanced_image = enhanced_image[:actual_enhanced_height, :actual_enhanced_width]\n",
    "\n",
    "    # Now crop back to original size\n",
    "    enhanced_image = enhanced_image[:original_height, :original_width]\n",
    "\n",
    "    return enhanced_image\n",
    "\n",
    "input_folder = '/home/gregrevill/code/GregRevFr/photopocalypse/raw_data/input_images/'\n",
    "output_folder = '/home/gregrevill/code/GregRevFr/photopocalypse/raw_data/output_images_modelv2/'\n",
    "\n",
    "# Get list of image file paths from the input directory\n",
    "image_files = [f for f in os.listdir(input_folder) if os.path.isfile(os.path.join(input_folder, f))]\n",
    "\n",
    "# Process each image\n",
    "for file_name in image_files:\n",
    "    image_path = os.path.join(input_folder, file_name)\n",
    "    enhanced_image = deblur_image(image_path)\n",
    "\n",
    "    # Create a new filename with 'deblurred' appended\n",
    "    new_filename = f\"deblurred_{file_name}\"\n",
    "    output_path = os.path.join(output_folder, new_filename)\n",
    "\n",
    "    # Save the enhanced image\n",
    "    cv2.imwrite(output_path, enhanced_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display original image and super resolution image side by side with labels\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Load the images\n",
    "img1 = mpimg.imread(image_path)\n",
    "img2 = mpimg.imread(enhanced_image)\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "# Display the images\n",
    "ax[0].imshow(img1)\n",
    "ax[0].set_title('Original Image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(img2)\n",
    "ax[1].set_title('Super Resolution Image')\n",
    "ax[1].axis('off')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Image not found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@236.512] global loadsave.cpp:248 findDecoder imread_('/home/gregrevill/code/GregRevFr/photopocalypse/raw_data/input_images/Photopocolypse_WBG.png'): can't open/read file: check file path/integrity\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def resize_and_save_image(image_path, output_folder, sizes):\n",
    "    \"\"\"\n",
    "    Resizes an image to multiple sizes and saves them.\n",
    "\n",
    "    :param image_path: Path to the original image.\n",
    "    :param output_folder: Folder where resized images will be saved.\n",
    "    :param sizes: List of tuple sizes to resize the image to. Example: [(800, 600), (1024, 768)]\n",
    "    \"\"\"\n",
    "    # Read the original image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        print(\"Error: Image not found.\")\n",
    "        return\n",
    "\n",
    "    for size in sizes:\n",
    "        # Resize the image\n",
    "        resized_image = cv2.resize(image, size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Construct the output file path\n",
    "        output_path = f\"{output_folder}/2_{size[0]}x{size[1]}.jpg\"\n",
    "\n",
    "        # Save the resized image\n",
    "        cv2.imwrite(output_path, resized_image)\n",
    "        print(f\"Image saved to {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "image_path = '/home/gregrevill/code/GregRevFr/photopocalypse/raw_data/input_images/Photopocolypse_WBG.png'\n",
    "output_folder = \"/home/gregrevill/code/GregRevFr/photopocalypse/raw_data/input_images/\"  # Replace with your desired output folder\n",
    "sizes = [(600, 600)]  # Different sizes for testing\n",
    "\n",
    "resize_and_save_image(image_path, output_folder, sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizes folder of images to 600x600\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "def resize_image(image_path, output_dir, size=(600, 600)):\n",
    "    if not os.path.isfile(image_path) or not image_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        height, width, channels = image.shape\n",
    "\n",
    "        if height > width:\n",
    "            image = image[0:width, 0:width] # crops from the bottom to make square\n",
    "\n",
    "        resized_image = cv2.resize(image, size, interpolation=cv2.INTER_AREA)\n",
    "        output_path = os.path.join(output_dir, os.path.basename(image_path))\n",
    "        cv2.imwrite(output_path, resized_image)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {image_path}: {e}\")\n",
    "\n",
    "image_dir = \"/home/gregrevill/code/GregRevFr/photopocalypse/raw_data/input_images/\"\n",
    "output_dir = \"/home/gregrevill/code/GregRevFr/photopocalypse/raw_data/input_images/600x600/\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for image_file in os.listdir(image_dir):\n",
    "    image_path = os.path.join(image_dir, image_file)\n",
    "    resize_image(image_path, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'RealESRGAN'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/gregrevill/code/GregRevFr/photopocalypse/notebooks/notebook_greg.ipynb Cell 14\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gregrevill/code/GregRevFr/photopocalypse/notebooks/notebook_greg.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gregrevill/code/GregRevFr/photopocalypse/notebooks/notebook_greg.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# pip install realesrgan\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gregrevill/code/GregRevFr/photopocalypse/notebooks/notebook_greg.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mRealESRGAN\u001b[39;00m \u001b[39mimport\u001b[39;00m RealESRGAN\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gregrevill/code/GregRevFr/photopocalypse/notebooks/notebook_greg.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gregrevill/code/GregRevFr/photopocalypse/notebooks/notebook_greg.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m model \u001b[39m=\u001b[39m RealESRGAN(device, scale\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'RealESRGAN'"
     ]
    }
   ],
   "source": [
    "# RealESRGAN model\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "# pip install realesrgan\n",
    "from RealESRGAN import RealESRGAN\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = RealESRGAN(device, scale=4)\n",
    "model.load_weights('weights/RealESRGAN_x4.pth', download=True)\n",
    "\n",
    "path_to_image = 'inputs/lr_image.png'\n",
    "image = Image.open(path_to_image).convert('RGB')\n",
    "\n",
    "sr_image = model.predict(image)\n",
    "\n",
    "sr_image.save('results/sr_image.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
